{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, auc, roc_curve, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the file saved after preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/4_final_dataset.csv').drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>authors</th>\n",
       "      <th>feature_combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>mumbai students protesting caa nrc wankhede st...</td>\n",
       "      <td>1391</td>\n",
       "      <td>eok4qb</td>\n",
       "      <td>https://i.redd.it/y4jcbkiedqa41.jpg</td>\n",
       "      <td>116</td>\n",
       "      <td>1970-01-01 00:00:01.579030566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gavthi_Batman</td>\n",
       "      <td>im extremely biased towards ktm duke 200 390 i...</td>\n",
       "      <td>I'm extremely biased towards the KTM Duke (bo...</td>\n",
       "      <td>mumbai students protesting caa nrc wankhede st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>amit shah looking source comment</td>\n",
       "      <td>16</td>\n",
       "      <td>fbx2it</td>\n",
       "      <td>https://i.redd.it/6heuj8xxf3k41.png</td>\n",
       "      <td>4</td>\n",
       "      <td>1970-01-01 00:00:01.583111542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sickcooler</td>\n",
       "      <td>im extremely biased towards ktm duke 200 390 i...</td>\n",
       "      <td>I'm extremely biased towards the KTM Duke (bo...</td>\n",
       "      <td>amit shah looking source comment im extremely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>real loser indias errupting islamaphobia caste...</td>\n",
       "      <td>81</td>\n",
       "      <td>g76o5f</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g76o5f...</td>\n",
       "      <td>53</td>\n",
       "      <td>1970-01-01 00:00:01.587756081</td>\n",
       "      <td>tldr unqualified opinion dalit political movem...</td>\n",
       "      <td>HairLikeWinterFire</td>\n",
       "      <td>im extremely biased towards ktm duke 200 390 i...</td>\n",
       "      <td>I'm extremely biased towards the KTM Duke (bo...</td>\n",
       "      <td>real loser indias errupting islamaphobia caste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>annual reminder indias ayush minister promised...</td>\n",
       "      <td>398</td>\n",
       "      <td>fu1ly8</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fu1ly8...</td>\n",
       "      <td>43</td>\n",
       "      <td>1970-01-01 00:00:01.585916565</td>\n",
       "      <td>spoiler dont please note said prevention cure ...</td>\n",
       "      <td>madamplease</td>\n",
       "      <td>im extremely biased towards ktm duke 200 390 i...</td>\n",
       "      <td>I'm extremely biased towards the KTM Duke (bo...</td>\n",
       "      <td>annual reminder indias ayush minister promised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>mp covid19 megathread</td>\n",
       "      <td>21</td>\n",
       "      <td>fpt2jw</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fpt2jw...</td>\n",
       "      <td>19</td>\n",
       "      <td>1970-01-01 00:00:01.585324794</td>\n",
       "      <td>thread sharing coronavirus news updates relate...</td>\n",
       "      <td>maardon_bhenji</td>\n",
       "      <td>im extremely biased towards ktm duke 200 390 i...</td>\n",
       "      <td>I'm extremely biased towards the KTM Duke (bo...</td>\n",
       "      <td>mp covid19 megathread im extremely biased towa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            flair  \\\n",
       "0  Politics -- Source in comments   \n",
       "1  Politics -- Source in comments   \n",
       "2  Politics -- Source in comments   \n",
       "3  Politics -- Source in comments   \n",
       "4  Politics -- Source in comments   \n",
       "\n",
       "                                               title  score      id  \\\n",
       "0  mumbai students protesting caa nrc wankhede st...   1391  eok4qb   \n",
       "1                   amit shah looking source comment     16  fbx2it   \n",
       "2  real loser indias errupting islamaphobia caste...     81  g76o5f   \n",
       "3  annual reminder indias ayush minister promised...    398  fu1ly8   \n",
       "4                              mp covid19 megathread     21  fpt2jw   \n",
       "\n",
       "                                                 url  comms_num  \\\n",
       "0                https://i.redd.it/y4jcbkiedqa41.jpg        116   \n",
       "1                https://i.redd.it/6heuj8xxf3k41.png          4   \n",
       "2  https://www.reddit.com/r/india/comments/g76o5f...         53   \n",
       "3  https://www.reddit.com/r/india/comments/fu1ly8...         43   \n",
       "4  https://www.reddit.com/r/india/comments/fpt2jw...         19   \n",
       "\n",
       "                         created  \\\n",
       "0  1970-01-01 00:00:01.579030566   \n",
       "1  1970-01-01 00:00:01.583111542   \n",
       "2  1970-01-01 00:00:01.587756081   \n",
       "3  1970-01-01 00:00:01.585916565   \n",
       "4  1970-01-01 00:00:01.585324794   \n",
       "\n",
       "                                                body              author  \\\n",
       "0                                                NaN       Gavthi_Batman   \n",
       "1                                                NaN          sickcooler   \n",
       "2  tldr unqualified opinion dalit political movem...  HairLikeWinterFire   \n",
       "3  spoiler dont please note said prevention cure ...         madamplease   \n",
       "4  thread sharing coronavirus news updates relate...      maardon_bhenji   \n",
       "\n",
       "                                            comments  \\\n",
       "0  im extremely biased towards ktm duke 200 390 i...   \n",
       "1  im extremely biased towards ktm duke 200 390 i...   \n",
       "2  im extremely biased towards ktm duke 200 390 i...   \n",
       "3  im extremely biased towards ktm duke 200 390 i...   \n",
       "4  im extremely biased towards ktm duke 200 390 i...   \n",
       "\n",
       "                                             authors  \\\n",
       "0   I'm extremely biased towards the KTM Duke (bo...   \n",
       "1   I'm extremely biased towards the KTM Duke (bo...   \n",
       "2   I'm extremely biased towards the KTM Duke (bo...   \n",
       "3   I'm extremely biased towards the KTM Duke (bo...   \n",
       "4   I'm extremely biased towards the KTM Duke (bo...   \n",
       "\n",
       "                                     feature_combine  \n",
       "0  mumbai students protesting caa nrc wankhede st...  \n",
       "1  amit shah looking source comment im extremely ...  \n",
       "2  real loser indias errupting islamaphobia caste...  \n",
       "3  annual reminder indias ayush minister promised...  \n",
       "4  mp covid19 megathread im extremely biased towa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split to training and testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = data.flair\n",
    "features = data.feature_combine\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=42, test_size=0.2)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(np.ravel(y_train.values)),\n",
    "                                                 np.ravel(y_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = np.unique(np.ravel(y_train.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function: conversion to one-hot vector for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vector(label):\n",
    "    temp = np.zeros(label.shape[0])\n",
    "    for i in range(label.shape[0]):\n",
    "        temp[i] = np.where(label[i] == 1)[0]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to try out multiple algorithms while trying out which algorithm performs best. The function takes a list of algorithms and returns the classification report for each of them. Takes quite a while as GradientBoosting does not support multithreading yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithms(algorithms, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    for algo in algorithms:\n",
    "        algorithm = Pipeline([('vect', CountVectorizer()),\n",
    "                             ('tfodf', TfidfTransformer()),\n",
    "                             ('clf', algo)], verbose=True)\n",
    "        print(algorithm)\n",
    "        algorithm.fit(X_train, y_train)\n",
    "        cv_scores = cross_val_score(algorithm, X_train, y_train, cv=5)\n",
    "        print('cv_scores:',cv_scores)\n",
    "        print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "        results[algorithm]= np.mean(cv_scores)\n",
    "        y_pred = algorithm.predict(X_test)\n",
    "        print(y_pred.shape)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    return results, algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining different algorithms to try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "clf = SVC(C=0.9, kernel='rbf')\n",
    "sgd = SGDClassifier(loss='hinge',\n",
    "                   penalty = 'l2',\n",
    "                   alpha = 1e-5,\n",
    "                   max_iter=5, tol = None)\n",
    "rfc = RandomForestClassifier(n_estimators=1000,\n",
    "                            random_state=42)\n",
    "\n",
    "xgb = xgboost.XGBClassifier(objective='multi:softmax',\n",
    "                            n_estimators=1000,\n",
    "                           random_state=42,\n",
    "                           learning_rate=0.001,\n",
    "                           n_jobs= 6,\n",
    "                           verbose=True)\n",
    "gbc = GradientBoostingClassifier(n_estimators=1000,\n",
    "                                learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [clf, dtc, rfc, sgd, gbc]\n",
    "\n",
    "#X_train = X_train.combined_features\n",
    "#X_test = X_test.combined_features\n",
    "res, mod = test_algorithms(algos, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning and training the best performing algorithm from pervious cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=Non...\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=1000, n_jobs=6,\n",
      "                               num_parallel_tree=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=None, reg_lambda=None,\n",
      "                               scale_pos_weight=None, subsample=None,\n",
      "                               tree_method=None, validate_parameters=False,\n",
      "                               verbose=True, verbosity=None))],\n",
      "         verbose=True)\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfodf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=10.3min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfodf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 9.3min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfodf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 9.6min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfodf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 9.2min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfodf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 9.0min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfodf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 8.2min\n",
      "cv_scores: [0.66875  0.703125 0.721875 0.709375 0.690625]\n",
      "cv_scores mean:0.6987500000000001\n"
     ]
    }
   ],
   "source": [
    "algorithm = Pipeline([('vect', CountVectorizer()),\n",
    "          ('tfodf', TfidfTransformer()),\n",
    "          ('clf', xgb)], verbose = True)\n",
    "print(algorithm)\n",
    "algorithm.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(algorithm, X_train, y_train, cv=5)\n",
    "print('cv_scores:',cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=Non...\n",
      "                                            loss='deviance', max_depth=3,\n",
      "                                            max_features=None,\n",
      "                                            max_leaf_nodes=None,\n",
      "                                            min_impurity_decrease=0.0,\n",
      "                                            min_impurity_split=None,\n",
      "                                            min_samples_leaf=1,\n",
      "                                            min_samples_split=2,\n",
      "                                            min_weight_fraction_leaf=0.0,\n",
      "                                            n_estimators=1000,\n",
      "                                            n_iter_no_change=None,\n",
      "                                            presort='deprecated',\n",
      "                                            random_state=None, subsample=1.0,\n",
      "                                            tol=0.0001, validation_fraction=0.1,\n",
      "                                            verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "cv_scores: [0.65     0.725    0.71875  0.65625  0.709375]\n",
      "cv_scores mean:0.691875\n"
     ]
    }
   ],
   "source": [
    "algorithm = Pipeline([('vect', CountVectorizer()),\n",
    "          ('tfodf', TfidfTransformer()),\n",
    "          ('clf', gbc)])\n",
    "print(algorithm)\n",
    "algorithm.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(algorithm, X_train, y_train, cv=5)\n",
    "print('cv_scores:',cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb_model.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(algorithm, \"gb_model.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                      AskIndia       0.94      0.71      0.81        24\n",
      "              Business/Finance       0.60      0.43      0.50        21\n",
      "                       CAA-NRC       0.91      0.84      0.87        25\n",
      "                   CAA-NRC-NPR       0.67      0.62      0.65        16\n",
      "                   Coronavirus       0.84      0.89      0.86        18\n",
      "                Demonetization       0.90      0.72      0.80        25\n",
      "                          Food       0.78      0.90      0.84        20\n",
      "                 Non-Political       0.89      0.94      0.92        18\n",
      "                           Old       0.82      0.78      0.80        18\n",
      "                   Photography       0.94      0.94      0.94        18\n",
      "              Policy & Economy       0.11      0.19      0.14        21\n",
      "                Policy/Economy       0.30      0.21      0.25        28\n",
      " Policy/Economy -2017 Article        0.26      0.28      0.27        18\n",
      "                      Politics       0.50      0.91      0.65        22\n",
      "Politics -- Source in comments       0.69      0.61      0.65        18\n",
      "                     Scheduled       0.87      0.76      0.81        17\n",
      "            Science/Technology       0.90      0.78      0.84        23\n",
      "                        Sports       0.93      0.74      0.82        19\n",
      "                  Totally real       0.72      0.81      0.76        16\n",
      "                    Unverified       0.79      0.73      0.76        15\n",
      "\n",
      "                      accuracy                           0.68       400\n",
      "                     macro avg       0.72      0.69      0.70       400\n",
      "                  weighted avg       0.71      0.68      0.69       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#results[algorithm]= np.mean(cv_scores)\n",
    "y_pred = algorithm.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  0  0  0  0  0  0  1  0  1  1  0  1  1  0  1  0  0  0  1]\n",
      " [ 1  9  0  0  0  0  1  0  1  0  5  0  1  0  0  1  1  0  1  0]\n",
      " [ 0  0 21  3  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  2 10  0  0  0  0  0  0  0  0  0  1  3  0  0  0  0  0]\n",
      " [ 0  0  0  0 16  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 18  1  0  2  0  0  0  0  2  1  0  0  0  1  0]\n",
      " [ 0  1  0  0  0  0 18  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  1  0  0 14  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  4 11  5  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  1  0  0  0  0 17  6  1  1  0  0  0  0  1  0]\n",
      " [ 0  2  0  1  0  0  1  0  0  0  5  2  5  1  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0  0  0  0  0 20  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  3  1 11  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  3  0 13  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  1  0  2  0  0  0 18  0  1  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0 14  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  0  0  1  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  1  0  0  0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "The model does not differentiate well between set of similar flairs: such as:\n",
    "Policy & Economy, Policy/Economy, Policy/Economy -2017 Article and CAA-NRC and CAA-NRC-NPR\n",
    "\n",
    "While this can be solved by merging the classes under consideration, it would techincally change the expected class during testing. This is not implemented yet. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The confusion matrix supports the above observation: the model does not work well with similar classes. \n",
    "However, other classes observe high precision and recall, and there are very few examples of false positives or false negatives. \n",
    "\n",
    "So, it has acceptable performace of most classes of flairs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
