{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, auc, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cleaned_data.csv').drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>authors</th>\n",
       "      <th>feature_combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>mumbai students protesting caa nrc wankhede st...</td>\n",
       "      <td>1395</td>\n",
       "      <td>eok4qb</td>\n",
       "      <td>https://i.redd.it/y4jcbkiedqa41.jpg</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1970-01-01 00:00:01.579030566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gavthi_Batman</td>\n",
       "      <td>found myfitnesspal pretty good indian food pac...</td>\n",
       "      <td>I found MyFitnessPal to be pretty good with I...</td>\n",
       "      <td>mumbai students protesting caa nrc wankhede st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>amit shah looking source comment</td>\n",
       "      <td>18</td>\n",
       "      <td>fbx2it</td>\n",
       "      <td>https://i.redd.it/6heuj8xxf3k41.png</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1970-01-01 00:00:01.583111542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sickcooler</td>\n",
       "      <td>found myfitnesspal pretty good indian food pac...</td>\n",
       "      <td>I found MyFitnessPal to be pretty good with I...</td>\n",
       "      <td>amit shah looking source comment found myfitne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>annual reminder indias ayush minister promised...</td>\n",
       "      <td>395</td>\n",
       "      <td>fu1ly8</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fu1ly8...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1970-01-01 00:00:01.585916565</td>\n",
       "      <td>spoiler dont please note said prevention cure ...</td>\n",
       "      <td>madamplease</td>\n",
       "      <td>found myfitnesspal pretty good indian food pac...</td>\n",
       "      <td>I found MyFitnessPal to be pretty good with I...</td>\n",
       "      <td>annual reminder indias ayush minister promised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>mp covid19 megathread</td>\n",
       "      <td>18</td>\n",
       "      <td>fpt2jw</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fpt2jw...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1970-01-01 00:00:01.585324794</td>\n",
       "      <td>thread sharing coronavirus news updates relate...</td>\n",
       "      <td>maardon_bhenji</td>\n",
       "      <td>found myfitnesspal pretty good indian food pac...</td>\n",
       "      <td>I found MyFitnessPal to be pretty good with I...</td>\n",
       "      <td>mp covid19 megathread found myfitnesspal prett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politics -- Source in comments</td>\n",
       "      <td>friends decades fallen fake news actively demo...</td>\n",
       "      <td>28</td>\n",
       "      <td>fvyodb</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvyodb...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1970-01-01 00:00:01.586208234</td>\n",
       "      <td>govt india failed miserably protecting doctors...</td>\n",
       "      <td>in3po</td>\n",
       "      <td>found myfitnesspal pretty good indian food pac...</td>\n",
       "      <td>I found MyFitnessPal to be pretty good with I...</td>\n",
       "      <td>friends decades fallen fake news actively demo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            flair  \\\n",
       "0  Politics -- Source in comments   \n",
       "1  Politics -- Source in comments   \n",
       "2  Politics -- Source in comments   \n",
       "3  Politics -- Source in comments   \n",
       "4  Politics -- Source in comments   \n",
       "\n",
       "                                               title  score      id  \\\n",
       "0  mumbai students protesting caa nrc wankhede st...   1395  eok4qb   \n",
       "1                   amit shah looking source comment     18  fbx2it   \n",
       "2  annual reminder indias ayush minister promised...    395  fu1ly8   \n",
       "3                              mp covid19 megathread     18  fpt2jw   \n",
       "4  friends decades fallen fake news actively demo...     28  fvyodb   \n",
       "\n",
       "                                                 url  comms_num  \\\n",
       "0                https://i.redd.it/y4jcbkiedqa41.jpg      116.0   \n",
       "1                https://i.redd.it/6heuj8xxf3k41.png        4.0   \n",
       "2  https://www.reddit.com/r/india/comments/fu1ly8...       43.0   \n",
       "3  https://www.reddit.com/r/india/comments/fpt2jw...       19.0   \n",
       "4  https://www.reddit.com/r/india/comments/fvyodb...        6.0   \n",
       "\n",
       "                         created  \\\n",
       "0  1970-01-01 00:00:01.579030566   \n",
       "1  1970-01-01 00:00:01.583111542   \n",
       "2  1970-01-01 00:00:01.585916565   \n",
       "3  1970-01-01 00:00:01.585324794   \n",
       "4  1970-01-01 00:00:01.586208234   \n",
       "\n",
       "                                                body          author  \\\n",
       "0                                                NaN   Gavthi_Batman   \n",
       "1                                                NaN      sickcooler   \n",
       "2  spoiler dont please note said prevention cure ...     madamplease   \n",
       "3  thread sharing coronavirus news updates relate...  maardon_bhenji   \n",
       "4  govt india failed miserably protecting doctors...           in3po   \n",
       "\n",
       "                                            comments  \\\n",
       "0  found myfitnesspal pretty good indian food pac...   \n",
       "1  found myfitnesspal pretty good indian food pac...   \n",
       "2  found myfitnesspal pretty good indian food pac...   \n",
       "3  found myfitnesspal pretty good indian food pac...   \n",
       "4  found myfitnesspal pretty good indian food pac...   \n",
       "\n",
       "                                             authors  \\\n",
       "0   I found MyFitnessPal to be pretty good with I...   \n",
       "1   I found MyFitnessPal to be pretty good with I...   \n",
       "2   I found MyFitnessPal to be pretty good with I...   \n",
       "3   I found MyFitnessPal to be pretty good with I...   \n",
       "4   I found MyFitnessPal to be pretty good with I...   \n",
       "\n",
       "                                     feature_combine  \n",
       "0  mumbai students protesting caa nrc wankhede st...  \n",
       "1  amit shah looking source comment found myfitne...  \n",
       "2  annual reminder indias ayush minister promised...  \n",
       "3  mp covid19 megathread found myfitnesspal prett...  \n",
       "4  friends decades fallen fake news actively demo...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.fillna(\"\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = data.flair\n",
    "features = data.feature_combine\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=42, test_size=0.2)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(np.ravel(y_train.values)),\n",
    "                                                 np.ravel(y_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = np.unique(np.ravel(y_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vector(label):\n",
    "    temp = np.zeros(label.shape[0])\n",
    "    for i in range(label.shape[0]):\n",
    "        temp[i] = np.where(label[i] == 1)[0]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithms(algorithms, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    for algo in algorithms:\n",
    "        algorithm = Pipeline([('vect', CountVectorizer()),\n",
    "                             ('tfodf', TfidfTransformer()),\n",
    "                             ('clf', algo)])\n",
    "        print(algorithm)\n",
    "        algorithm.fit(X_train, y_train)\n",
    "        cv_scores = cross_val_score(algorithm, X_train, y_train, cv=5)\n",
    "        print('cv_scores:',cv_scores)\n",
    "        print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "        results[algorithm]= np.mean(cv_scores)\n",
    "        y_pred = algorithm.predict(X_test)\n",
    "        print(y_pred.shape)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "clf = SVC(C=0.9, kernel='rbf')\n",
    "sgd = SGDClassifier(loss='hinge',\n",
    "                   penalty = 'l2',\n",
    "                   alpha = 1e-5,\n",
    "                   max_iter=5, tol = None)\n",
    "rfc = RandomForestClassifier(n_estimators=1000,\n",
    "                            random_state=42)\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=1000,\n",
    "                                learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=Non...\n",
      "                                            loss='deviance', max_depth=3,\n",
      "                                            max_features=None,\n",
      "                                            max_leaf_nodes=None,\n",
      "                                            min_impurity_decrease=0.0,\n",
      "                                            min_impurity_split=None,\n",
      "                                            min_samples_leaf=1,\n",
      "                                            min_samples_split=2,\n",
      "                                            min_weight_fraction_leaf=0.0,\n",
      "                                            n_estimators=1000,\n",
      "                                            n_iter_no_change=None,\n",
      "                                            presort='deprecated',\n",
      "                                            random_state=None, subsample=1.0,\n",
      "                                            tol=0.0001, validation_fraction=0.1,\n",
      "                                            verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores: [0.64759036 0.68975904 0.71686747 0.67975831 0.69486405]\n",
      "cv_scores mean:0.6857678447930695\n",
      "(415,)\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                      AskIndia       0.95      0.76      0.84        25\n",
      "              Business/Finance       0.75      0.50      0.60        24\n",
      "                       CAA-NRC       0.94      0.71      0.81        24\n",
      "                   CAA-NRC-NPR       0.71      0.86      0.77        14\n",
      "                   Coronavirus       0.75      0.91      0.82        23\n",
      "                Demonetization       0.94      0.70      0.80        23\n",
      "                          Food       0.85      0.68      0.76        25\n",
      "                 Non-Political       0.93      0.93      0.93        14\n",
      "       Official Sadness Thread       0.00      0.00      0.00         0\n",
      "                           Old       1.00      0.61      0.76        18\n",
      "               Original Comics       1.00      0.60      0.75         5\n",
      "                   Photography       0.88      1.00      0.93        14\n",
      "              Policy & Economy       0.18      0.21      0.19        24\n",
      "                Policy/Economy       0.19      0.24      0.21        17\n",
      " Policy/Economy -2017 Article        0.50      0.55      0.52        11\n",
      "                      Politics       0.25      0.57      0.35        21\n",
      "Politics -- Source in comments       0.64      0.78      0.70        18\n",
      "         Politics [Megathread]       0.00      0.00      0.00         1\n",
      "                     Scheduled       0.80      0.70      0.74        23\n",
      "            Science/Technology       0.92      0.88      0.90        25\n",
      "                        Sports       0.92      0.80      0.86        15\n",
      "                  Totally real       0.75      0.79      0.77        19\n",
      "                    Unverified       0.95      0.73      0.83        26\n",
      "                     Zoke Tyme       1.00      1.00      1.00         4\n",
      "                 [R]eddiquette       1.00      0.50      0.67         2\n",
      "\n",
      "                      accuracy                           0.69       415\n",
      "                     macro avg       0.71      0.64      0.66       415\n",
      "                  weighted avg       0.75      0.69      0.71       415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "algos = [clf, dtc, rfc, sgd, gbc]\n",
    "algos = [gbc]\n",
    "\n",
    "#X_train = X_train.combined_features\n",
    "#X_test = X_test.combined_features\n",
    "res = test_algorithms(algos, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=Non...\n",
      "                                            loss='deviance', max_depth=3,\n",
      "                                            max_features=None,\n",
      "                                            max_leaf_nodes=None,\n",
      "                                            min_impurity_decrease=0.0,\n",
      "                                            min_impurity_split=None,\n",
      "                                            min_samples_leaf=1,\n",
      "                                            min_samples_split=2,\n",
      "                                            min_weight_fraction_leaf=0.0,\n",
      "                                            n_estimators=1000,\n",
      "                                            n_iter_no_change=None,\n",
      "                                            presort='deprecated',\n",
      "                                            random_state=None, subsample=1.0,\n",
      "                                            tol=0.0001, validation_fraction=0.1,\n",
      "                                            verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores: [0.64759036 0.68975904 0.71385542 0.67975831 0.69486405]\n",
      "cv_scores mean:0.6851654351545153\n"
     ]
    }
   ],
   "source": [
    "algorithm = Pipeline([('vect', CountVectorizer()),\n",
    "          ('tfodf', TfidfTransformer()),\n",
    "          ('clf', gbc)])\n",
    "print(algorithm)\n",
    "algorithm.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(algorithm, X_train, y_train, cv=5)\n",
    "print('cv_scores:',cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415,)\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                      AskIndia       0.95      0.72      0.82        25\n",
      "              Business/Finance       0.75      0.50      0.60        24\n",
      "                       CAA-NRC       0.89      0.71      0.79        24\n",
      "                   CAA-NRC-NPR       0.71      0.86      0.77        14\n",
      "                   Coronavirus       0.75      0.91      0.82        23\n",
      "                Demonetization       0.94      0.65      0.77        23\n",
      "                          Food       0.85      0.68      0.76        25\n",
      "                 Non-Political       0.93      0.93      0.93        14\n",
      "       Official Sadness Thread       0.00      0.00      0.00         0\n",
      "                           Old       1.00      0.61      0.76        18\n",
      "               Original Comics       1.00      0.60      0.75         5\n",
      "                   Photography       0.88      1.00      0.93        14\n",
      "              Policy & Economy       0.18      0.21      0.19        24\n",
      "                Policy/Economy       0.20      0.24      0.22        17\n",
      " Policy/Economy -2017 Article        0.50      0.55      0.52        11\n",
      "                      Politics       0.24      0.57      0.34        21\n",
      "Politics -- Source in comments       0.64      0.78      0.70        18\n",
      "         Politics [Megathread]       0.00      0.00      0.00         1\n",
      "                     Scheduled       0.76      0.70      0.73        23\n",
      "            Science/Technology       0.92      0.88      0.90        25\n",
      "                        Sports       0.92      0.80      0.86        15\n",
      "                  Totally real       0.75      0.79      0.77        19\n",
      "                    Unverified       0.95      0.73      0.83        26\n",
      "                     Zoke Tyme       1.00      1.00      1.00         4\n",
      "                 [R]eddiquette       1.00      0.50      0.67         2\n",
      "\n",
      "                      accuracy                           0.68       415\n",
      "                     macro avg       0.71      0.64      0.66       415\n",
      "                  weighted avg       0.75      0.68      0.70       415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#results[algorithm]= np.mean(cv_scores)\n",
    "y_pred = algorithm.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb_model.sav']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(algorithm, \"gb_model.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
